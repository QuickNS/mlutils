{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from mlutils.nlp import *\n",
    "from mlutils.models.classification import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from fastai.text.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "#!gunzip aclImdb_v1.tar.gz\n",
    "#!tar -xvf aclImdb_v1.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB dataset and the sentiment classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/) contains a collection of 50,000 reviews from IMDB. The dataset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. Neutral reviews are not included in the dataset. The dataset is divided into training and test sets. The training set is the same 25,000 labeled reviews.\n",
    "\n",
    "The **sentiment classification task** consists of predicting the polarity (positive or negative) of a given text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and term document matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='aclImdb/'\n",
    "names = ['neg','pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdbEr.txt  imdb.vocab  README  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeledBow.feat  \u001b[0m\u001b[01;34mpos\u001b[0m/    unsupBow.feat  urls_pos.txt\r\n",
      "\u001b[01;34mneg\u001b[0m/             \u001b[01;34munsup\u001b[0m/  urls_neg.txt   urls_unsup.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls {PATH}train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_9.txt\r\n",
      "10000_8.txt\r\n",
      "10001_10.txt\r\n",
      "10002_7.txt\r\n",
      "10003_8.txt\r\n",
      "10004_8.txt\r\n",
      "10005_7.txt\r\n",
      "10006_7.txt\r\n",
      "10007_7.txt\r\n",
      "10008_7.txt\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "%ls {PATH}train/pos | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_labels_from_folders(path, folders):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(folders):\n",
    "        for fname in glob(os.path.join(path, label, '*.*')):\n",
    "            texts.append(open(fname, 'r').read())\n",
    "            labels.append(idx)\n",
    "    return texts, np.array(labels).astype(np.int64)\n",
    "\n",
    "trn,trn_y = texts_labels_from_folders(f'{PATH}train',names)\n",
    "val,val_y = texts_labels_from_folders(f'{PATH}test',names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adrian has just gone out of the asylum, being rich and with no parents, his life seems empty. One day, he meets Gonzalo, a poor boy whom mother is prostitute. Desperate for earning some money, Gonzalo helps Adrian to search about his life and who where his parents. This is a movie from a new director, and it is perfectly clear in most of the film: scenes not correctly directed, dialogues a little forced, some incoherences in the script...Anyway, the ending is unexpectedly well done (well, just a little) and that saves a little the film. Actors are known and with great quality, nevertheless, they are not inspired enough to make the movie interesting; all of them have done better papers in other film. The film results boring and probably you will spend most of the time thinking how much time will pass until it ends. Of course there are lots of worse films, but, sure, there are many many better ones.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[trn_y[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our vectorizer and transform to create a document matrix\n",
    "trn_term_doc = veczr.fit_transform(trn)\n",
    "# apply the bag of words to the validation data\n",
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x75132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3749745 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25k documents with 75132 word vocabulary\n",
    "trn_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x75132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 113 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this particular review has 67 identified words\n",
    "trn_term_doc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aussie', 'aussies', 'austen', 'austeniana', 'austens']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which words are in the bag of words model?\n",
    "vocab = veczr.get_feature_names();\n",
    "vocab[5000:5005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(well,',\n",
       " 'a',\n",
       " 'about',\n",
       " 'actors',\n",
       " 'adrian',\n",
       " 'all',\n",
       " 'and',\n",
       " 'are',\n",
       " 'asylum,',\n",
       " 'being',\n",
       " 'better',\n",
       " 'boring',\n",
       " 'boy',\n",
       " 'but,',\n",
       " 'clear',\n",
       " 'correctly',\n",
       " 'course',\n",
       " 'day,',\n",
       " 'desperate',\n",
       " 'dialogues',\n",
       " 'directed,',\n",
       " 'director,',\n",
       " 'done',\n",
       " 'earning',\n",
       " 'empty.',\n",
       " 'ending',\n",
       " 'ends.',\n",
       " 'enough',\n",
       " 'film',\n",
       " 'film.',\n",
       " 'film:',\n",
       " 'films,',\n",
       " 'for',\n",
       " 'forced,',\n",
       " 'from',\n",
       " 'gone',\n",
       " 'gonzalo',\n",
       " 'gonzalo,',\n",
       " 'great',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'helps',\n",
       " 'his',\n",
       " 'how',\n",
       " 'in',\n",
       " 'incoherences',\n",
       " 'inspired',\n",
       " 'interesting;',\n",
       " 'is',\n",
       " 'it',\n",
       " 'just',\n",
       " 'known',\n",
       " 'life',\n",
       " 'little',\n",
       " 'little)',\n",
       " 'lots',\n",
       " 'make',\n",
       " 'many',\n",
       " 'meets',\n",
       " 'money,',\n",
       " 'most',\n",
       " 'mother',\n",
       " 'movie',\n",
       " 'much',\n",
       " 'nevertheless,',\n",
       " 'new',\n",
       " 'no',\n",
       " 'not',\n",
       " 'of',\n",
       " 'one',\n",
       " 'ones.',\n",
       " 'other',\n",
       " 'out',\n",
       " 'papers',\n",
       " 'parents,',\n",
       " 'parents.',\n",
       " 'pass',\n",
       " 'perfectly',\n",
       " 'poor',\n",
       " 'probably',\n",
       " 'prostitute.',\n",
       " 'quality,',\n",
       " 'results',\n",
       " 'rich',\n",
       " 'saves',\n",
       " 'scenes',\n",
       " 'script...anyway,',\n",
       " 'search',\n",
       " 'seems',\n",
       " 'some',\n",
       " 'spend',\n",
       " 'sure,',\n",
       " 'that',\n",
       " 'the',\n",
       " 'them',\n",
       " 'there',\n",
       " 'they',\n",
       " 'thinking',\n",
       " 'this',\n",
       " 'time',\n",
       " 'to',\n",
       " 'unexpectedly',\n",
       " 'until',\n",
       " 'well',\n",
       " 'where',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'will',\n",
       " 'with',\n",
       " 'worse',\n",
       " 'you'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# go to raw data to naively split words\n",
    "w0 = set([o.lower() for o in trn[6].split(' ')]);\n",
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# almost the same, except we didn't use a tokenizer here\n",
    "len(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8484"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veczr.vocabulary_['boring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the word boring appears on this review\n",
    "trn_term_doc[6, 8484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66458"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look for irrelevant words\n",
    "veczr.vocabulary_['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have quite a few \"the\" on this text\n",
    "trn_term_doc[6, 66458]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just created a Bag of Words model, based on the vocabulary found through all the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training and validation sets\n",
    "x=trn_term_doc\n",
    "y=trn_y\n",
    "x_val = val_term_doc\n",
    "y_val = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Training): 0.99632\n",
      "Accuracy score: 0.85752\n"
     ]
    }
   ],
   "source": [
    "# train classifier\n",
    "m = LogisticRegression(C=1e8, dual=True)\n",
    "train_classification(m, x, y);\n",
    "preds = predict_and_evaluate_classification(m, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the regularized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Training): 0.99644\n",
      "Accuracy score: 0.87184\n"
     ]
    }
   ],
   "source": [
    "# train classifier\n",
    "m = LogisticRegression(C=1.0, dual=True)\n",
    "train_classification(m, x, y);\n",
    "preds = predict_and_evaluate_classification(m, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Training): 0.99784\n",
      "Accuracy score: 0.87384\n"
     ]
    }
   ],
   "source": [
    "# binarized \n",
    "m = LogisticRegression(C=1.0, dual=True)\n",
    "train_classification(m, x.sign(), y);\n",
    "preds = predict_and_evaluate_classification(m, x_val.sign(), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram with NB features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr =  CountVectorizer(ngram_range=(1,3), tokenizer=tokenize, max_features=800000)\n",
    "trn_term_doc = veczr.fit_transform(trn)\n",
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 800000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by vast', 'by vengeance', 'by vengeance .', 'by vera', 'by vera miles']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = veczr.get_feature_names()\n",
    "vocab[200000:200005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training and validation sets\n",
    "x=trn_term_doc.sign()\n",
    "y=trn_y\n",
    "x_val = val_term_doc.sign()\n",
    "y_val = val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegressor with trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Training): 1.0\n",
      "Accuracy score: 0.90140\n"
     ]
    }
   ],
   "source": [
    "# train classifier\n",
    "m = LogisticRegression(C=1e8, dual=True)\n",
    "train_classification(m, x, y);\n",
    "preds = predict_and_evaluate_classification(m, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Naive-Bayes features\n",
    "def pr(y_i):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "r = np.log(pr(1) / pr(0))\n",
    "b = np.log((y==1).mean() / (y==0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegressor with trigram's log-count ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Training): 0.99928\n",
      "Accuracy score: 0.91768\n"
     ]
    }
   ],
   "source": [
    "x_nb = x.multiply(r)\n",
    "val_x_nb = x_val.multiply(r)\n",
    "\n",
    "m = LogisticRegression(dual=True, C=0.1)\n",
    "train_classification(m, x_nb, y);\n",
    "preds = predict_and_evaluate_classification(m, val_x_nb, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
